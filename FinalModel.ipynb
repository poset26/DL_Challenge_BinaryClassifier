{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-07T11:13:12.595670Z",
     "start_time": "2024-12-07T11:13:09.618204Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T11:13:12.643265Z",
     "start_time": "2024-12-07T11:13:12.604888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataLoader:\n",
    "\n",
    "    def __init__(self, dataset, batch_size=32, val_split=0.2):\n",
    "\n",
    "        self.dataset = dataset\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "\n",
    "        train_size =len(self.dataset)\n",
    "\n",
    "        train_dataset, _ = torch.utils.data.random_split(self.dataset, [train_size, len(self.dataset) - train_size])\n",
    "\n",
    "        return DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "\n",
    "    transforms.Resize((224, 224)),\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "\n",
    "])\n",
    "\n",
    "image_dir = '/home/taiel/dl2425_challenge_dataset/dl2425_challenge_dataset/train'\n",
    "test_dir = '/home/taiel/dl2425_challenge_dataset/dl2425_challenge_dataset/val'\n",
    "dataset = datasets.ImageFolder(root=image_dir, transform=transform)\n",
    "testdataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "Data_Loader = DataLoader(dataset)\n",
    "testloader = DataLoader(testdataset)\n"
   ],
   "id": "cb2e01cbc4491c51",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T11:13:12.735648Z",
     "start_time": "2024-12-07T11:13:12.717509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "\n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "\n",
    "        x = self.relu(self.batch_norm2(self.conv2(x)))\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "\n",
    "        # downsample if needed\n",
    "        if self.i_downsample is not None:\n",
    "            identity = self.i_downsample(identity)\n",
    "        # add identity\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "\n",
    "        x = self.relu(self.batch_norm2(self.conv1(x)))\n",
    "        x = self.batch_norm2(self.conv2(x))\n",
    "\n",
    "        if self.i_downsample is not None:\n",
    "            identity = self.i_downsample(identity)\n",
    "        print(x.shape)\n",
    "        print(identity.shape)\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResBlock, layer_list, num_classes, num_channels=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(ResBlock, layer_list[0], planes=64)\n",
    "        self.layer2 = self._make_layer(ResBlock, layer_list[1], planes=128, stride=2)\n",
    "        self.layer3 = self._make_layer(ResBlock, layer_list[2], planes=256, stride=2)\n",
    "        self.layer4 = self._make_layer(ResBlock, layer_list[3], planes=512, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * ResBlock.expansion, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, ResBlock, blocks, planes, stride=1):\n",
    "        ii_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        if stride != 1 or self.in_channels != planes * ResBlock.expansion:\n",
    "            ii_downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, planes * ResBlock.expansion, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes * ResBlock.expansion)\n",
    "            )\n",
    "\n",
    "        layers.append(ResBlock(self.in_channels, planes, i_downsample=ii_downsample, stride=stride))\n",
    "        self.in_channels = planes * ResBlock.expansion\n",
    "\n",
    "        for i in range(blocks - 1):\n",
    "            layers.append(ResBlock(self.in_channels, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def ResNet50(num_classes, channels=3):\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3], num_classes, channels)\n",
    "\n",
    "\n",
    "def ResNet101(num_classes, channels=3):\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3], num_classes, channels)\n",
    "\n",
    "\n",
    "def ResNet152(num_classes, channels=3):\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3], num_classes, channels)\n",
    "\n",
    "def ResNet304(num_classes, channels=3):\n",
    "    return ResNet(Bottleneck, [3, 18, 48, 3], num_classes, channels)"
   ],
   "id": "8fb311b608c073c9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T11:13:12.776116Z",
     "start_time": "2024-12-07T11:13:12.769899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(6, 96)  # First fully connected layer\n",
    "        self.fc2 = nn.Linear(96, 48)  # Second fully connected layer\n",
    "        self.fc3 = nn.Linear(48, 16)  # Third fully connected layer\n",
    "        self.fc4 = nn.Linear(16, 1)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        return x"
   ],
   "id": "1a45aa02480f9b0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T11:13:18.081213Z",
     "start_time": "2024-12-07T11:13:18.073514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * 28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 32)\n",
    "        self.fc6 = nn.Linear(32, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 256 * 28 * 28)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ],
   "id": "115a22b9daa568bd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "net, rn50, and rn304 are each trained separately to classify the images. Then the fmodel (cnn) is trained to take as input the output of the three resnet models and produce as output a number between 0 and 1 (no fire and fire).",
   "id": "620864cddba7c910"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "net = ResNet152(2).to(device)\n",
    "#net.load_state_dict(torch.load(\"resnet_152_checkpoint_69.pth\",map_location=device))\n",
    "\n",
    "rn50 = ResNet50(2).to(device)\n",
    "#rn50.load_state_dict(torch.load('resnet_50_checkpoint_119.pth', map_location=device))\n",
    "\n",
    "rn304 = ResNet304(2).to(device)\n",
    "#rn304.load_state_dict(torch.load('resnet_304_checkpoint_68.pth', map_location=device))\n",
    "fmodel = CNN().to(device)\n",
    "model = CNNModel(num_classes=2).to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)"
   ],
   "id": "203ab498bc4d648d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train(EPOCHS):\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        losses = []\n",
    "\n",
    "        running_loss = 0\n",
    "\n",
    "        for i, inp in enumerate(Data_Loader.train_dataloader()):\n",
    "            inputs, labels = inp\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "            if i%100 == 0 and i > 0:\n",
    "\n",
    "                print(f'Loss [{epoch+1}, {i}](epoch, minibatch): ', running_loss / 100)\n",
    "\n",
    "                running_loss = 0.0\n",
    "    \n",
    "\n",
    "\n",
    "        avg_loss = sum(losses)/len(losses)\n",
    "\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(vcheck(net))\n",
    "            torch.save(net.state_dict(),f\"resnet_50_checkpoint_{epoch}.pth\")\n",
    "\n",
    "\n",
    "\n",
    "print('Training Done')"
   ],
   "id": "72ceccbe9c7c3c91"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_fmodel(EPOCHS):\n",
    "    for epoch in range(EPOCHS):\n",
    "        criterion = nn.BCELoss()  # Binary Cross Entropy Loss (final layer of the model is sigmoid)\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=0.01)\n",
    "        losses = []\n",
    "\n",
    "        running_loss = 0\n",
    "\n",
    "        for i, inp in enumerate(Data_Loader.train_dataloader()):\n",
    "\n",
    "            inputs, labels = inp\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            images, labels = inputs, labels\n",
    "            outputsa = net(images)\n",
    "            outputsb = rn50(images)\n",
    "            outputsc = rn304(images)\n",
    "            a,b,c = outputsa,outputsb, outputsc\n",
    "            input_tensor = torch.stack((a, b, c), dim=2)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_tensor)\n",
    "            loss = criterion(outputs,torch.tensor(labels, dtype=torch.float32).view(32,1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if i%100 == 0 and i > 0:\n",
    "\n",
    "                print(f'Loss [{epoch+1}, {i}](epoch, minibatch): ', running_loss / 100)\n",
    "\n",
    "                running_loss = 0.0\n",
    "            del inputs, labels, images, outputsa, outputsb, outputsc, a, b, c, input_tensor, outputs, loss\n",
    "            torch.save(model.state_dict(),f\"model_2_{epoch}.pth\")\n",
    "\n",
    "\n",
    "    print('Training Done')"
   ],
   "id": "487f90540cf09ff1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
